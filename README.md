# 主动学习优化项目

这个仓库包含主动学习优化项目的源代码，用于高维函数优化的研究。

## 主要组件

- **Rosenbrock函数优化**：使用主动学习优化Rosenbrock测试函数
- **Schwefel函数优化**：使用协同进化模拟退火（CSA）等方法优化Schwefel测试函数

## 项目结构

- `rosenbrock/`: Rosenbrock函数优化的代码和工具
- `schwefel/`: Schwefel函数优化的代码和工具，包括CSA实现

## 安装和使用

请参考各子目录中的environment.yml或requirements.txt进行环境配置。

# 基于模拟退火的主动学习Pipeline - Schwefel函数优化

## 项目概述

本项目实现了一个基于模拟退火（Simulated Annealing, SA）的主动学习流水线，用于优化schwefel函数。针对Schwefel函数的特殊结构（各维度独立贡献且直接相加），设计了维度分解神经网络模型来解决高维问题中高斯过程(GP)计算复杂度高、性能下降的局限性。主要目标是从当前未标注样本中进行学习，预测出该函数全局最小值的解，最大化在有限标注预算下的优化效果。输出为top20个最小值的解。

## 主动学习流程


## 核心组件

### 1. 代理模型 (SurrogateModel)
- 基于维度分解的神经网络架构
- 使用混合损失函数：`Loss = α × MSE + (1-α) × (1-Pearson相关系数)`
- 支持数据归一化和早停机制
- 自动保存训练过程的可视化结果

### 2. 搜索策略 (SearchStrategy)
- 协同进化模拟退火算法
- 将20维问题分解为独立子问题
- 每轮进行3次模拟退火搜索
- 动态调整探索权重

### 3. 主动学习优化器 (ActiveLearningOptimizer)
- 整合代理模型和搜索策略
- 支持3次主动学习迭代
- 每次迭代包含模型训练和搜索过程
- 自动记录和可视化优化过程

## 主要特性

1. **高效优化**
   - 维度分解降低问题复杂度
   - 协同进化加速收敛
   - 自适应探索策略

### 2. 自动分解神经网络 (AutoDecomposedNetwork)
**核心思想**：
- 利用Schwefel函数的可加性结构（每个维度独立贡献），使用一个共享参数的子网络处理所有维度
- 参数共享大幅减少模型参数量，提高训练效率
- 各维度输出直接相加得到最终预测值

**数学表达式**：
$$\hat{f}(\mathbf{x}) = \sum_{i=1}^{d} \hat{f}_i(x_i)$$

其中 $\hat{f}_i(x_i)$ 是对第i个维度输入的预测。

**模型架构**：
- **子网络 (SubNetwork)**：
  - 处理单个维度的输入
  - 包含多个隐藏层，每层包含线性变换、批量归一化、LeakyReLU激活和Dropout
  - 参数在所有维度间共享，显著减少模型复杂度

- **自动分解网络**：
  - 包含一个共享子网络处理所有维度
  - 前向传播时将输入拆分为单独维度，分别通过子网络，再将结果求和

**训练方法**：
- **并行训练策略**：同时考虑所有维度的贡献
- **混合损失函数**：结合MSE和Pearson相关系数，同时优化数值差异和相关性
- **学习率动态调整**：根据验证性能自动调整学习率

### 3. 搜索策略（SA+维度分解探索）
**核心优化方案**：

**维度协同模拟退火**：
- 将SA算法应用于每个维度的独立优化
- 每个维度有独立的温度参数和邻域生成策略
- 基于维度重要性动态分配计算资源

**温度控制**：
- 初始温度设置：$T_0 = \frac{\ln(2)}{\max(f(x))-\min(f(x))}$（基于初始解的函数值差异）
- 降温策略：$T_{n+1} = T_n \cdot \alpha$ (α=0.98，缓慢降温以避免早熟)

**候选解生成**：
- **维度分解探索**：
  - 对每个维度独立执行优化搜索，生成维度候选值
  - 根据维度重要性分配探索资源
  - 组合各维度候选值，生成完整的20维候选解
- **邻域扰动策略**：
  - 每个维度模型提供梯度信息
  - $x'_i = x_{current,i} + \eta \cdot \nabla \hat{f}_i(x_{current,i}) + \epsilon \cdot T$
  - 其中η是梯度步长（0.1），ε是高斯噪声，扰动幅度与温度T成正比

**信息导向的采样策略**：
- 使用维度分解模型的预测值和不确定性估计
- $Score(x) = \hat{f}(x) + \beta \cdot \sigma(x)$ (β=2)
- 选择分数最低的候选解（优先探索低函数值且高不确定性的区域）

### 4. 标签验证
**流程设计**：
- **候选解提交**：每次迭代选择20个候选解（通过维度分解SA和神经网络联合评分）提交验证
- **真实函数计算**：对候选解计算Schwefel函数真实值: $f(x) = 418.9829 \cdot n - \sum_{i=1}^{n} x_i \sin(\sqrt{|x_i|})$（20维）
- **数据库更新**：将验证后的样本标记为"已标注"，并更新数据库

### 5. 模型重训练
**增量更新机制**：
- **触发条件**：每次标签验证后立即触发
- **训练策略**：
  - 对每个维度模型进行独立更新
  - 使用新增的标注数据增量训练各维度模型
  - 计算各维度模型的预测误差，动态调整训练参数和资源分配
- **维度重要性分析**：
  - 通过方差分析识别对优化结果影响较大的关键维度
  - 对重要维度分配更多计算资源和搜索次数

## Schwefel函数

Schwefel函数是一个著名的测试函数，用于评估优化算法的性能。它是一个多峰函数，具有多个局部最优解，全局最优解远离局部最优解，对优化算法提出了挑战。数学表达式为：

$$f(x) = 418.9829 \times d - \sum_{i=1}^{d} [x_i \times \sin(\sqrt{|x_i|})]$$

其中d是维度，x_i是决策变量。

**关键特性**：
- **可加性结构**：每个维度的贡献是独立的，最终结果是各维度计算后直接相加
- **无维度耦合**：不存在维度之间的交叉项或相互影响
- **高维挑战**：在高维情况下(d=20)，传统高斯过程模型计算复杂度高(O(n³))且效果下降

## 主要流程

1. **初始化阶段**：
   - 数据库初始化：随机选择20个样本作为初始标注数据
   - 模型初始化：初始化自动分解神经网络模型

2. **迭代阶段（三次循环）**：
   - **维度分解SA搜索**：
     - 对每个维度独立执行优化搜索，生成维度候选值
     - 组合各维度候选值，生成完整的20维候选解
   
   - **候选评估与选择**：
     - 使用自动分解神经网络评估候选解的函数值
     - 计算每个维度的重要性贡献，动态调整搜索权重
     - 选择20个最具潜力的候选解进行真实评估
   
   - **标签验证**：计算选中样本的真实函数值，更新数据库
   
   - **模型重训练**：
     - 用新标注数据更新自动分解神经网络模型
     - 计算各维度模型的预测误差，调整训练参数

3. **评估阶段**：
   - 在测试集上评估最终模型性能
   - 计算性能提升并可视化结果
   - 输出top20个最优解

## 与传统高斯过程方法对比

| 方法 | 计算复杂度 | 高维性能 | 内存需求 | 并行性 |
|------|------------|----------|----------|--------|
| 高斯过程 | O(n³) | 随维度增加急剧下降 | 高（需存储n×n协方差矩阵） | 较差 |
| 自动分解神经网络 | O(n×d) | 保持稳定 | 低 | 优秀（可并行训练） |

## 针对性优化方案

**神经网络架构优化**：
- 针对Schwefel函数的周期性特性设计包含正弦激活的特殊层
- 为提高稳定性和加速收敛，使用批量归一化和LeakyReLU激活函数

**热启动训练**：
- 利用每次迭代的经验积累，避免模型从零开始训练
- 保留并微调前一次迭代的模型权重，加速收敛

**维度重要性驱动的计算资源分配**：
- 动态评估每个维度对优化进度的贡献
- 对关键维度分配更多计算资源，提高整体效率

## 运行方法

1. 确保数据文件 `Schwefel_x_train.npy`, `Schwefel_y_train.npy`, `Schwefel_x_test.npy`, `Schwefel_y_test.npy` 在上级目录中

2. 设置conda环境：
   ```bash
   # 使用环境配置文件创建环境
   conda env create -f environment.yml
   
   # 激活环境
   conda activate schwefel_sa
   
   # 或者使用现有的优化脚本（推荐）
   bash setup_cuda11_8_env.sh
   conda activate mlenv
   ```

3. 运行优化：
   ```bash
   # 使用默认参数的GPU加速
   ./run_gpu.sh
   
   # 或者使用交互式UI运行
   python main.py
   
   # 对于更高级的GPU优化（适用于1080Ti）
   ./run_gpu_advanced.sh
   ```

4. 查看结果：
   - 运行过程中会输出每次迭代的评估结果和每个维度的优化进度
   - 可视化结果将保存在 `results/` 目录下

## GPU加速说明

本项目针对CUDA 11.8和NVIDIA 1080Ti进行了优化，支持以下GPU加速特性：

1. **RAPIDS cuML加速**：
   - 使用GPU加速的随机森林模型，大幅提升训练速度
   - 自动检测并利用可用的GPU资源

2. **TensorFlow GPU加速**：
   - 启用XLA（加速线性代数）计算
   - 支持混合精度训练（FP16/FP32）
   - 智能显存管理，避免OOM错误

3. **优化配置选项**：
   - 自适应批处理大小
   - 维度重要性驱动的资源分配
   - 高级环境变量优化

4. **使用建议**：
   - 对于大规模问题（高维度），推荐使用`run_gpu_advanced.sh`脚本
   - 对于小规模问题，使用交互式`main.py`或`run_gpu.sh`脚本
   - 内存有限的环境可以通过降低批处理大小来适应 

   当前代码中的逻辑（已修复后）：
初始化: 如果从文件加载数据，会使用 objective_function 计算初始 y_samples 的真值。
训练替代模型: _train_surrogate_model 使用当前的 self.x_samples 和 self.y_samples（这些 y_samples 是通过 objective_function 计算得到的真值）来训练替代模型 (self.surrogate_model)。
模拟退火搜索 (sa_search.search):
我们调用 sa_search.search 时，传入了 objective_function 和 surrogate_model。
关键点：在我们上一次的修改中，SimulatedAnnealingSearch.search 方法内部被修正为：如果提供了已训练的 surrogate_model，它会优先使用 surrogate_model.predict 来评估候选解的好坏。这是因为它更快、计算成本更低。
因此，模拟退火搜索实际上是依据替代模型的预测值来寻找有希望的区域和解 (best_solution)，而不是直接调用昂贵的 objective_function。传递 objective_function 主要是为了提供一个备选方案（以防替代模型不可用）并且符合该方法原始的参数设计，但在主动学习迭代中，它依赖的是替代模型。
生成和评估Top 20候选解:
_generate_candidates 在模拟退火找到的 best_solution 附近生成一些候选点。
这些候选点首先通过替代模型 (self.surrogate_model.predict) 进行评估，以快速筛选出预测值最低的20个样本 (top_candidates)。
获取真值 (专家评估):
这最关键的一步：程序调用 self.objective_function (专家模型) 来计算这 top_candidates 的真实函数值 (top_values)。
top_values = np.array([self.objective_function(x) for x in top_candidates])
更新数据集:
将这 20 个包含了真实函数值 (top_values) 的样本 (top_candidates) 添加到 self.x_samples 和 self.y_samples 中。
下一轮迭代: 进入下一轮迭代时，会使用这个扩充了真实样本的数据集重新训练替代模型。